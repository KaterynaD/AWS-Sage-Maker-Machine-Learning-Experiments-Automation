{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments_file='/home/kate/Research/YearBuilt/Experiments/Experiments.xlsx'\n",
    "AllExperiments_tab='Experiments'\n",
    "Experiment_name='Overfitting'\n",
    "#Experiment configuration: differenet datasets to try\n",
    "#each line in the file contains the model name and set of features to built a dataset for SageMaker\n",
    "Experiment_tab='%s Models'%Experiment_name\n",
    "\n",
    "#Looks like Trial name should be unique in my environment, not in the experiment it belongs to\n",
    "Trial_name='%s-PreparingTrainValidData'%Experiment_name\n",
    "\n",
    "\n",
    "\n",
    "#original dataset was created from a Redshift query and uploaded into S3\n",
    "bucket='kdproperty'\n",
    "path_to_data_file='/Data/'\n",
    "data_file='property_basedata_v3.csv'\n",
    "target='hasclaim'\n",
    "split_year='2020'\n",
    "training_dataset_sizes=['0.7','0.65','0.6','0.55','0.5','0.45','0.4','0.35']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/kate/Research/YearBuilt/Notebooks/Property')\n",
    "import ExperimentsUtils as eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "#delete experiment and trials but not output files associated with jobs in experiments\n",
    "eu.cleanup_experiment(Experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "eu.create_experiment(Experiment_name)\n",
    "eu.create_trial(Experiment_name,Trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FinalModel</td>\n",
       "      <td>roofcd_encd</td>\n",
       "      <td>usagetype_encd</td>\n",
       "      <td>cova_deductible</td>\n",
       "      <td>cova_limit</td>\n",
       "      <td>sqft</td>\n",
       "      <td>yearbuilt</td>\n",
       "      <td>landlordind</td>\n",
       "      <td>water_risk_3_blk</td>\n",
       "      <td>constructioncd_encd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model           F1              F2               F3           F4  \\\n",
       "0  FinalModel  roofcd_encd  usagetype_encd  cova_deductible  cova_limit    \n",
       "\n",
       "     F5           F6           F7                F8                   F9  \n",
       "0  sqft  yearbuilt    landlordind  water_risk_3_blk  constructioncd_encd  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.read_excel(open(Experiments_file, 'rb'), sheet_name=Experiment_tab)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kdproperty'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "role = 'arn:aws:iam::757107622481:role/service-role/AmazonSageMaker-ExecutionRole-20200819T131882'\n",
    "sagemaker_session = sagemaker.session.Session(default_bucket=bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessingBatchesToTestOverfiiting.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessingBatchesToTestOverfiiting.py\n",
    "\n",
    "#Training and Validation dataset for SageMaker are the same structure: no headers, the first column is a target and the rest are features\n",
    "\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_file', type=str)\n",
    "    parser.add_argument('--split_year', type=int)    \n",
    "    parser.add_argument('--target', type=str)     \n",
    "    parser.add_argument('--model', type=str)\n",
    "    parser.add_argument('--featureset', type=str)  \n",
    "    parser.add_argument('--training_dataset_sizes', type=str) \n",
    "    args, _ = parser.parse_known_args()   \n",
    "    \n",
    "    print('Received arguments {}'.format(args))\n",
    "    \n",
    "    featureset=args.featureset.split(',')\n",
    "    target_column=args.target\n",
    "    training_dataset_sizes=args.training_dataset_sizes.split(',')\n",
    "    input_data_path = os.path.join('/opt/ml/processing/input', args.data_file)\n",
    "    train_data_output_path = '/opt/ml/processing/output/training_data'  \n",
    "    validation_data_output_path = '/opt/ml/processing/output/validation_data'\n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    print('Reading input data from {}'.format(input_data_path))\n",
    "    dataset = pd.read_csv(input_data_path, error_bad_lines=False, index_col=False)\n",
    "    \n",
    "    \n",
    "    dataset=dataset[(dataset.cal_year < args.split_year)][featureset + [target_column]]\n",
    "    \n",
    "    X = dataset[featureset]\n",
    "    y = dataset[target_column]\n",
    "    \n",
    "    for s in training_dataset_sizes:\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=1 - float(s), random_state=42)\n",
    "       \n",
    "        \n",
    "        train_data_output_path_batch = os.path.join(train_data_output_path,  'batch_%s_training_%s.csv'%(s,args.model))    \n",
    "        validation_data_output_path_batch = os.path.join(validation_data_output_path, 'batch_%s_validation_%s.csv'%(s,args.model))\n",
    "     \n",
    "        \n",
    "        training_dataset=pd.DataFrame({'hasclaim':y_train}).join(X_train)\n",
    "        training_dataset.to_csv(train_data_output_path_batch, header=False, index=False)\n",
    "                                                   \n",
    "        validation_dataset=pd.DataFrame({'hasclaim':y_val}).join(X_val)   \n",
    "        validation_dataset.to_csv(validation_data_output_path_batch, header=False, index=False)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need several different size datasets for each model. I can not use N pairs of ProcessingOutput for training and validation data because of some errors related to size of parameters(? not data size)\n",
    "So I save 10 files in each training and validation folders with batch_0, batch_1 etc addition in front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Creating datasets for model FinalModel\n",
      "usagetype_encd,cova_deductible,cova_limit ,sqft,yearbuilt  ,landlordind,water_risk_3_blk,constructioncd_encd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n",
      "INFO:sagemaker:Creating processing-job with name sagemaker-scikit-learn-2020-12-17-17-53-30-180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2020-12-17-17-53-30-180\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://kdproperty/Data/property_basedata_v3.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-757107622481/sagemaker-scikit-learn-2020-12-17-17-53-30-180/input/code/preprocessingBatchesToTestOverfiiting.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'training_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-west-2-757107622481/sagemaker-scikit-learn-2020-12-17-17-53-30-180/output/training_data', 'LocalPath': '/opt/ml/processing/output/training_data', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'validation_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-west-2-757107622481/sagemaker-scikit-learn-2020-12-17-17-53-30-180/output/validation_data', 'LocalPath': '/opt/ml/processing/output/validation_data', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "processors=list()\n",
    "\n",
    "for index, row in models.iterrows():\n",
    "    model=row['Model']\n",
    "    print (index, ': Creating datasets for model %s'%model)\n",
    "    featureset=row[1:51].tolist()\n",
    "    featureset=[x for x in featureset if str(x) != 'nan']\n",
    "    print(','.join(featureset))\n",
    "    data_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.t3.medium',\n",
    "                                     instance_count=1,\n",
    "                                     tags=[{'Key': 'Model', 'Value':model},\n",
    "                                           {'Key': 'Featureset', 'Value': ':'.join(featureset)},\n",
    "                                           {'Key': 'split_year','Value':split_year},\n",
    "                                           {'Key': 'training_dataset_sizes','Value':':'.join(training_dataset_sizes)},])\n",
    "\n",
    "    data_processor.run(code='preprocessingBatchesToTestOverfiiting.py',\n",
    "                        inputs=[ProcessingInput(\n",
    "                        source='s3://%s%s'%(bucket,path_to_data_file+data_file),\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "                        outputs=[ProcessingOutput(output_name='training_data', source='/opt/ml/processing/output/training_data'),                                 \n",
    "                                 ProcessingOutput(output_name='validation_data', source='/opt/ml/processing/output/validation_data'),                                 \n",
    "                                ],\n",
    "                        arguments=['--data_file',data_file,\n",
    "                                 '--split_year',split_year,    \n",
    "                                 '--target',target,                                     \n",
    "                                 '--model',model,\n",
    "                                 '--featureset', ','.join(featureset).replace(' ',''),\n",
    "                                 '--training_dataset_sizes', ','.join(training_dataset_sizes) \n",
    "                                  ],\n",
    "                       experiment_config = {\n",
    "        'ExperimentName': Experiment_name ,\n",
    "        'TrialName' : Trial_name,\n",
    "        'TrialComponentDisplayName' : '%s-%s'%(Trial_name,model.replace('_','-')),},\n",
    "                    wait=False\n",
    "                     )\n",
    "    processors.append(data_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing job sagemaker-scikit-learn-2020-12-17-17-53-30-180 status: InProgress\n",
      "Continue waiting...\n",
      "Processing job sagemaker-scikit-learn-2020-12-17-17-53-30-180 status: InProgress\n",
      "Continue waiting...\n",
      "Processing job sagemaker-scikit-learn-2020-12-17-17-53-30-180 status: InProgress\n",
      "Continue waiting...\n",
      "Processing job sagemaker-scikit-learn-2020-12-17-17-53-30-180 status: InProgress\n",
      "Continue waiting...\n",
      "Processing job sagemaker-scikit-learn-2020-12-17-17-53-30-180 status: InProgress\n",
      "Continue waiting...\n",
      "Processing job sagemaker-scikit-learn-2020-12-17-17-53-30-180 status: InProgress\n",
      "Continue waiting...\n",
      "Processing job sagemaker-scikit-learn-2020-12-17-17-53-30-180 status: InProgress\n",
      "Continue waiting...\n",
      "Processing job sagemaker-scikit-learn-2020-12-17-17-53-30-180 status: InProgress\n",
      "Continue waiting...\n",
      "Processing job sagemaker-scikit-learn-2020-12-17-17-53-30-180 status: InProgress\n",
      "Continue waiting...\n",
      "All Processing Jobs are Completed\n"
     ]
    }
   ],
   "source": [
    "#wait till the rest of processing jobs complete\n",
    "eu.wait_processing_jobs(processors=processors,check_every_sec=15,print_every_n_output=6,wait_min=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When all jobs are done I want to have the list of training and validation data created in each job/trail component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Trial Component</th>\n",
       "      <th>Training_data</th>\n",
       "      <th>Validation_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FinalModel</td>\n",
       "      <td>Overfitting-PreparingTrainValidData-FinalModel</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model                                 Trial Component  \\\n",
       "0  FinalModel  Overfitting-PreparingTrainValidData-FinalModel   \n",
       "\n",
       "                                       Training_data  \\\n",
       "0  s3://sagemaker-us-west-2-757107622481/sagemake...   \n",
       "\n",
       "                                     Validation_data  \n",
       "0  s3://sagemaker-us-west-2-757107622481/sagemake...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=Experiment_name\n",
    ")\n",
    "trial_comp_ds = trial_component_analytics.dataframe()\n",
    "trial_ds=trial_comp_ds[trial_comp_ds['DisplayName'].str.contains(Trial_name)].copy()\n",
    "trial_ds['Model']=trial_ds['DisplayName'].str.replace(Trial_name+'-','')\n",
    "trial_ds['Model']=trial_ds['Model'].str.replace('-','_')\n",
    "trial_ds=trial_ds[['Model','DisplayName','training_data - Value','validation_data - Value']]\n",
    "trial_ds.columns=['Model','Trial Component','Training_data','Validation_data']\n",
    "trial_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an actual file name because we need to traine separate models on separate folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Trial Component</th>\n",
       "      <th>Training_data</th>\n",
       "      <th>Validation_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FinalModel_batch_0.7</td>\n",
       "      <td>Overfitting-PreparingTrainValidData-FinalModel</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FinalModel_batch_0.65</td>\n",
       "      <td>Overfitting-PreparingTrainValidData-FinalModel</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FinalModel_batch_0.6</td>\n",
       "      <td>Overfitting-PreparingTrainValidData-FinalModel</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FinalModel_batch_0.55</td>\n",
       "      <td>Overfitting-PreparingTrainValidData-FinalModel</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FinalModel_batch_0.5</td>\n",
       "      <td>Overfitting-PreparingTrainValidData-FinalModel</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FinalModel_batch_0.45</td>\n",
       "      <td>Overfitting-PreparingTrainValidData-FinalModel</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FinalModel_batch_0.4</td>\n",
       "      <td>Overfitting-PreparingTrainValidData-FinalModel</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FinalModel_batch_0.35</td>\n",
       "      <td>Overfitting-PreparingTrainValidData-FinalModel</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "      <td>s3://sagemaker-us-west-2-757107622481/sagemake...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                 Trial Component  \\\n",
       "0   FinalModel_batch_0.7  Overfitting-PreparingTrainValidData-FinalModel   \n",
       "1  FinalModel_batch_0.65  Overfitting-PreparingTrainValidData-FinalModel   \n",
       "2   FinalModel_batch_0.6  Overfitting-PreparingTrainValidData-FinalModel   \n",
       "3  FinalModel_batch_0.55  Overfitting-PreparingTrainValidData-FinalModel   \n",
       "4   FinalModel_batch_0.5  Overfitting-PreparingTrainValidData-FinalModel   \n",
       "5  FinalModel_batch_0.45  Overfitting-PreparingTrainValidData-FinalModel   \n",
       "6   FinalModel_batch_0.4  Overfitting-PreparingTrainValidData-FinalModel   \n",
       "7  FinalModel_batch_0.35  Overfitting-PreparingTrainValidData-FinalModel   \n",
       "\n",
       "                                       Training_data  \\\n",
       "0  s3://sagemaker-us-west-2-757107622481/sagemake...   \n",
       "1  s3://sagemaker-us-west-2-757107622481/sagemake...   \n",
       "2  s3://sagemaker-us-west-2-757107622481/sagemake...   \n",
       "3  s3://sagemaker-us-west-2-757107622481/sagemake...   \n",
       "4  s3://sagemaker-us-west-2-757107622481/sagemake...   \n",
       "5  s3://sagemaker-us-west-2-757107622481/sagemake...   \n",
       "6  s3://sagemaker-us-west-2-757107622481/sagemake...   \n",
       "7  s3://sagemaker-us-west-2-757107622481/sagemake...   \n",
       "\n",
       "                                     Validation_data  \n",
       "0  s3://sagemaker-us-west-2-757107622481/sagemake...  \n",
       "1  s3://sagemaker-us-west-2-757107622481/sagemake...  \n",
       "2  s3://sagemaker-us-west-2-757107622481/sagemake...  \n",
       "3  s3://sagemaker-us-west-2-757107622481/sagemake...  \n",
       "4  s3://sagemaker-us-west-2-757107622481/sagemake...  \n",
       "5  s3://sagemaker-us-west-2-757107622481/sagemake...  \n",
       "6  s3://sagemaker-us-west-2-757107622481/sagemake...  \n",
       "7  s3://sagemaker-us-west-2-757107622481/sagemake...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_l=list()\n",
    "Trial_Component_l=list()\n",
    "Training_data_l=list()\n",
    "Validation_data_l=list()\n",
    "for s in training_dataset_sizes:\n",
    "    for index, row in trial_ds.iterrows():\n",
    "        Model_l.append('%s_batch_%s'%(row['Model'],s))\n",
    "        Trial_Component_l.append(row['Trial Component'])\n",
    "        Training_data_l.append('%s/batch_%s_training_%s.csv'%(row['Training_data'],s,row['Model']))\n",
    "        Validation_data_l.append('%s/batch_%s_validation_%s.csv'%(row['Validation_data'],s,row['Model']))        \n",
    "trial_ds_extended = pd.DataFrame(list(zip(Model_l,Trial_Component_l,Training_data_l,Validation_data_l)), \n",
    "               columns =['Model','Trial Component','Training_data','Validation_data']).sort_values('Model', ascending=False)\n",
    "trial_ds_extended        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving into the Experiment log file names of created training and validation datasets in S3 to train models in other module  \n",
    "eu.SaveToExperimentLog(Experiments_file, '%s InputData'%Experiment_name, trial_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
