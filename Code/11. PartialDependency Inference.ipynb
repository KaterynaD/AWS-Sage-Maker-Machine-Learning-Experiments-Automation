{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments_file='/home/kate/Research/YearBuilt/Experiments/DwellingExperiments.xlsx'\n",
    "AllExperiments_tab='Experiments'\n",
    "Experiment_name='PartDepFWC'\n",
    "#Experiment configuration:\n",
    "#1.InputData is one line output frrom PreparingData trial. Only first line is used if more then 1 present\n",
    "Experiment_InputData_tab='%s InputData'%Experiment_name\n",
    "#2.ModelFiles: each line is a model name (Model) and full model file name (ModelData - model.tar.gz) in an S3 bucket\n",
    "Experiment_ModelFiles_tab='%s ModelFiles'%Experiment_name\n",
    "\n",
    "#Looks like Trial name should be unique in my environment, not in the experiment it belongs to\n",
    "Trial_name='%s-Inference'%Experiment_name\n",
    " \n",
    "bucket='kdproperty'\n",
    "s3_batch_output = 's3://%s/PartialDependency/'%(bucket)\n",
    "\n",
    "#number of instances can be teh same as number of features/files in InputData\n",
    "instance_type='ml.m5.xlarge'\n",
    "instance_count=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "from sagemaker.analytics import ExperimentAnalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "role = 'arn:aws:iam::757107622481:role/service-role/AmazonSageMaker-ExecutionRole-20200819T131882'\n",
    "sagemaker_session = sagemaker.session.Session(default_bucket=bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/kate/Research/YearBuilt/Notebooks/Property')\n",
    "import ExperimentsUtils as eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete experiment and trials but not output files associated with jobs in experiments\n",
    "#eu.cleanup_experiment(Experiment_name)\n",
    "#eu.cleanup_trial(Experiment_name, Trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "eu.create_experiment(Experiment_name)\n",
    "eu.create_trial(Experiment_name,Trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://kdproperty/Data/PartialDependencyInputData/PartDepFWC\n"
     ]
    }
   ],
   "source": [
    "#all models are predict from one dataset (in first row)\n",
    "InputData = pd.read_excel(open(Experiments_file, 'rb'), sheet_name=Experiment_InputData_tab)\n",
    "print(InputData['Data'][0])\n",
    "s3_batch_input = InputData['Data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Trial Component</th>\n",
       "      <th>ModelData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FWaterClaims</td>\n",
       "      <td>FWaterClaims-TrainingModels-FWaterClaims</td>\n",
       "      <td>s3://kdproperty/FWaterClaims-2020-12-31-20-15-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model                           Trial Component  \\\n",
       "0  FWaterClaims  FWaterClaims-TrainingModels-FWaterClaims   \n",
       "\n",
       "                                           ModelData  \n",
       "0  s3://kdproperty/FWaterClaims-2020-12-31-20-15-...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_ModelFiles = pd.read_excel(open(Experiments_file, 'rb'), sheet_name=Experiment_ModelFiles_tab)\n",
    "models_ModelFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sagemaker_xgboost_container.encoder as xgb_encoders\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Deserialize and return fitted model.\n",
    "    \"\"\"\n",
    "    model_file = \"xgboost-model\"\n",
    "    booster = pkl.load(open(os.path.join(model_dir, model_file), \"rb\"))\n",
    "    return booster\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"\n",
    "    The SageMaker XGBoost model server receives the request data body and the content type,\n",
    "    and invokes the `input_fn`.\n",
    "\n",
    "    Return a DMatrix (an object that can be passed to predict_fn).\n",
    "    \"\"\"\n",
    "    if request_content_type == \"text/csv\":\n",
    "        return xgb_encoders.csv_to_dmatrix(request_body.rstrip('\\n').lstrip('\\n'))\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Content type {} is not supported.\".format(request_content_type)\n",
    "        )\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"\n",
    "    SageMaker XGBoost model server invokes `predict_fn` on the return value of `input_fn`.\n",
    "\n",
    "    Return a two-dimensional NumPy array where the first columns are predictions\n",
    "    \"\"\"\n",
    "    prediction = model.predict(input_data)\n",
    "    return  prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FWaterClaims s3://kdproperty/FWaterClaims-2020-12-31-20-15-33/output/model.tar.gz\n",
      "FWaterClaims model does not exist\n",
      "FWaterClaims model was created\n"
     ]
    }
   ],
   "source": [
    "#Models to be used in prediction\n",
    "#based on model files provided in models_ModelFiles\n",
    "models = list()\n",
    "model_names = list()\n",
    "i = 0\n",
    "for index, row in models_ModelFiles.iterrows():\n",
    "    #Try to delete if exists model and create a new model based on a model file\n",
    "    name=row['Model']\n",
    "    name=name.replace('_','-')\n",
    "    model_data=row['ModelData']\n",
    "    print(name,model_data)\n",
    "    try:\n",
    "        response = smclient.delete_model(ModelName=name)\n",
    "        print('%s model was deleted'%name)\n",
    "    except:\n",
    "        print('%s model does not exist'%name)\n",
    "        pass\n",
    "    xgb_inference_model = XGBoostModel(\n",
    "    name=name,\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    entry_point='inference.py',\n",
    "    framework_version=\"1.0-1\",\n",
    "    )\n",
    "    models.append(xgb_inference_model)\n",
    "    model_names.append(name)\n",
    "    print('%s model was created'%name)\n",
    "    i = i + 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FWaterClaims s3://kdproperty/PartialDependency/FWaterClaims\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: FWaterClaims\n",
      "INFO:sagemaker:Creating transform job with name: FWaterClaims-2020-12-31-20-40-48-727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job FWaterClaims-2020-12-31-20-40-48-727 started\n"
     ]
    }
   ],
   "source": [
    "#create transformer job for each model\n",
    "tranform_jobs = list()\n",
    "tranformers = list()\n",
    "i = 0\n",
    "for m,model_name in zip(models,model_names):       \n",
    "    s3_batch_output_model=s3_batch_output+model_name\n",
    "    print(model_name,s3_batch_output_model)\n",
    "    transformer =  m.transformer(\n",
    "                                              instance_count=instance_count, \n",
    "                                              instance_type=instance_type,\n",
    "                                              output_path=s3_batch_output_model,\n",
    "                                              accept='text/csv',\n",
    "                                              strategy='MultiRecord',\n",
    "                                              assemble_with='Line'\n",
    "                                             )\n",
    "    tranformers.append(transformer)\n",
    "    transformer.transform(data=s3_batch_input, content_type='text/csv',split_type='Line', wait=False,\n",
    "    experiment_config = {\n",
    "        'ExperimentName': Experiment_name ,\n",
    "        'TrialName' : Trial_name,\n",
    "        'TrialComponentDisplayName' : '%s-%s'%(Trial_name,model_name.replace('_','-')),})\n",
    "    job_name = transformer.latest_transform_job.name\n",
    "    tranform_jobs.append(job_name)\n",
    "    print('Job %s started'%job_name)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming job FWaterClaims-2020-12-31-20-40-48-727 status: InProgress\n",
      "Continue waiting...\n",
      "Transforming job FWaterClaims-2020-12-31-20-40-48-727 status: InProgress\n",
      "Continue waiting...\n",
      "Transforming job FWaterClaims-2020-12-31-20-40-48-727 status: InProgress\n",
      "Continue waiting...\n",
      "Transforming job FWaterClaims-2020-12-31-20-40-48-727 status: InProgress\n",
      "Continue waiting...\n",
      "Transforming job FWaterClaims-2020-12-31-20-40-48-727 status: InProgress\n",
      "Continue waiting...\n",
      "Transforming job FWaterClaims-2020-12-31-20-40-48-727 status: InProgress\n",
      "Continue waiting...\n",
      "Transforming job FWaterClaims-2020-12-31-20-40-48-727 status: InProgress\n",
      "Continue waiting...\n",
      "Transforming job FWaterClaims-2020-12-31-20-40-48-727 status: InProgress\n",
      "Continue waiting...\n",
      "Transforming job FWaterClaims-2020-12-31-20-40-48-727 status: InProgress\n",
      "Continue waiting...\n",
      "Transforming job FWaterClaims-2020-12-31-20-40-48-727 status: InProgress\n",
      "Continue waiting...\n",
      "All Transforming Jobs are Completed\n"
     ]
    }
   ],
   "source": [
    "eu.wait_transform_jobs(processors=tranformers,tranform_jobs=tranform_jobs,check_every_sec=10,print_every_n_output=6,wait_min=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=Experiment_name\n",
    ")\n",
    "trial_comp_ds = trial_component_analytics.dataframe()\n",
    "trial_ds=trial_comp_ds[trial_comp_ds['DisplayName'].str.contains(Trial_name)].copy()\n",
    "trial_ds['Model']=trial_ds['DisplayName'].str.replace(Trial_name+'-','')\n",
    "trial_ds['Model']=trial_ds['Model'].str.replace('-','_')\n",
    "#trial_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FWaterClaims</td>\n",
       "      <td>PartDepFWC-Inference-FWaterClaims</td>\n",
       "      <td>s3://kdproperty/PartialDependency/FWaterClaims</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model                        DisplayName  \\\n",
       "0  FWaterClaims  PartDepFWC-Inference-FWaterClaims   \n",
       "\n",
       "                                             Data  \n",
       "0  s3://kdproperty/PartialDependency/FWaterClaims  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction Result files\n",
    "PredictedData = trial_ds[['Model','DisplayName','SageMaker.TransformOutput - Value']]\n",
    "PredictedData.columns=['Model','DisplayName','Data']\n",
    "PredictedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving into the Experiment log file testing data prediction files\n",
    "eu.SaveToExperimentLog(Experiments_file, '%s PredictedData'%Experiment_name, PredictedData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
