{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments_file='/home/kate/Research/YearBuilt/Experiments/DwellingExperiments.xlsx'\n",
    "AllExperiments_tab='Experiments'\n",
    "Experiment_name='PartDepFWC'\n",
    "#Experiment configuration:  features we want to produce PartialDependency\n",
    "#each line in the file contains a feature name and a type:Categorical or Continuous\n",
    "#Categorical features values will be process all as is. Continuous only sorted(np.linspace(np.percentile(dataset_temp[f], 0.1),np.percentile(dataset_temp[f], 99.5),50))\n",
    "Experiment_Features_tab='%s Features'%Experiment_name\n",
    "#Features Values Input Data: output of Create dataset for PartialDependency:one line with S3 folder with data for all models\n",
    "Experiment_InputData_tab='%s InputData'%Experiment_name\n",
    "#Predicted data:each line is a Model name and folder with prediction files. File name is a feature name\n",
    "Experiment_PredictedData_tab='%s PredictedData'%Experiment_name\n",
    "#The full set of features the tested model is based on\n",
    "#each line in the file contains the model name and set of features to built a dataset for SageMaker\n",
    "#only one,first row is taken into account\n",
    "Experiment_Models_tab='%s Models'%Experiment_name\n",
    "\n",
    "#Looks like Trial name should be unique in my environment, not in the experiment it belongs to\n",
    "Trial_name='%s-PostProcessing'%Experiment_name\n",
    " \n",
    "bucket='kdproperty'\n",
    "path_to_data_file='/Data/'\n",
    "\n",
    "\n",
    "instance_type='ml.t3.2xlarge'\n",
    "instance_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#to read data from S3 with pandas\n",
    "import s3fs\n",
    "\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "from sagemaker.analytics import ExperimentAnalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "role = 'arn:aws:iam::757107622481:role/service-role/AmazonSageMaker-ExecutionRole-20200819T131882'\n",
    "sagemaker_session = sagemaker.session.Session(default_bucket=bucket)\n",
    "s3 = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/kate/Research/YearBuilt/Notebooks/Property')\n",
    "import ExperimentsUtils as eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "#delete experiment and trials but not output files associated with jobs in experiments\n",
    "#eu.cleanup_experiment(Experiment_name)\n",
    "eu.cleanup_trial(Experiment_name, Trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "eu.create_experiment(Experiment_name)\n",
    "eu.create_trial(Experiment_name,Trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasclaim_water\n",
      "dwelling_basedata_v4.csv\n"
     ]
    }
   ],
   "source": [
    "experiments = pd.read_excel(open(Experiments_file, 'rb'), sheet_name=AllExperiments_tab)\n",
    "target=experiments[experiments['Experiment']==Experiment_name]['Target'].values[0]\n",
    "print(target)\n",
    "data_file=experiments[experiments['Experiment']==Experiment_name]['Dataset'].values[0]\n",
    "print(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['usagetype_encd',\n",
       " 'cova_deductible',\n",
       " 'cova_limit ',\n",
       " 'sqft',\n",
       " 'cal_year - yearbuilt',\n",
       " 'landlordind',\n",
       " 'water_risk_3_blk',\n",
       " 'constructioncd_encd']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take into account only one,first row \n",
    "#all models have the same dataset predicted from with teh same structure\n",
    "models = pd.read_excel(open(Experiments_file, 'rb'), sheet_name=Experiment_Models_tab)\n",
    "for index, row in models.iterrows():\n",
    "    model_complete_featureset=row[1:51].tolist()\n",
    "    model_complete_featureset=[x for x in model_complete_featureset if str(x) != 'nan']\n",
    "    break\n",
    "model_complete_featureset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cal_year - yearbuilt</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature        Type\n",
       "0  cal_year - yearbuilt  Continuous"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features = pd.read_excel(open(Experiments_file, 'rb'), sheet_name=Experiment_Features_tab)\n",
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FWaterClaims</td>\n",
       "      <td>PartDepFWC-Inference-FWaterClaims</td>\n",
       "      <td>s3://kdproperty/PartialDependency/FWaterClaims</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model                        DisplayName  \\\n",
       "0  FWaterClaims  PartDepFWC-Inference-FWaterClaims   \n",
       "\n",
       "                                             Data  \n",
       "0  s3://kdproperty/PartialDependency/FWaterClaims  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictedData = pd.read_excel(open(Experiments_file, 'rb'), sheet_name=Experiment_PredictedData_tab)\n",
    "PredictedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial Component</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PartDepFWC-PreparingData</td>\n",
       "      <td>s3://kdproperty/Data/PartialDependencyInputDat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Trial Component                                               Data\n",
       "0  PartDepFWC-PreparingData  s3://kdproperty/Data/PartialDependencyInputDat..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InputData = pd.read_excel(open(Experiments_file, 'rb'), sheet_name=Experiment_InputData_tab)\n",
    "InputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input data for post processing\n",
    "#1.Main dataset\n",
    "inputs=[ProcessingInput(source='s3://%s%s'%(bucket,path_to_data_file+data_file),\n",
    "                        destination='/opt/ml/processing/input')]\n",
    "\n",
    "#2.preprocessed features data for inference \n",
    "#need only 1st row for all models\n",
    "#theye are predicted from teh same dataset\n",
    "for index, row in InputData.iterrows():\n",
    "    inputs.append(ProcessingInput(source=row['Data'],\n",
    "                        destination='/opt/ml/processing/input/InputData'))\n",
    "    break\n",
    "\n",
    "\n",
    "#3.inference (prediction) data from each model\n",
    "for index, row in PredictedData.iterrows():\n",
    "    inputs.append(ProcessingInput(source=row['Data'],\n",
    "                        destination='/opt/ml/processing/input/PartialDependency/%s'%row['Model'].replace('_','-')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting postprocessingPartialDependencyData.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile postprocessingPartialDependencyData.py\n",
    "\n",
    "#The code joins InputData files for each feature and inference from each model and then average by each feature value\n",
    "\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_file', type=str)\n",
    "    parser.add_argument('--models', type=str)      \n",
    "    parser.add_argument('--model_complete_featureset', type=str)    \n",
    "    parser.add_argument('--featureset', type=str)   \n",
    "    parser.add_argument('--featuretypes', type=str)        \n",
    "    args, _ = parser.parse_known_args()    \n",
    "    print('Received arguments {}'.format(args))\n",
    "    \n",
    "    models=args.models.split(',')\n",
    "    model_complete_featureset=args.model_complete_featureset.split(',')    \n",
    "    featureset=args.featureset.split(',')\n",
    "    featuretypes=args.featuretypes.split(',')\n",
    "    \n",
    "    #original data file\n",
    "    input_data_path = os.path.join('/opt/ml/processing/input', args.data_file)\n",
    "    output_data_path = os.path.join('/opt/ml/processing/output', 'data.csv', )\n",
    "    \n",
    "    \n",
    "    print('Reading input data from {}'.format(input_data_path))\n",
    "    dataset = pd.read_csv(input_data_path, error_bad_lines=False, index_col=False)\n",
    "\n",
    "    #final dataset - average pd by each feature value\n",
    "    all_fm_pd = pd.DataFrame()\n",
    "    \n",
    "    for f,ftype in zip(featureset,featuretypes):\n",
    "        print('Processing %s'%f)\n",
    "        if ftype=='Continuous':\n",
    "            feature_InputData_dataset=pd.DataFrame()\n",
    "            for j in range(0,5):\n",
    "                feature_InputData_path=os.path.join('/opt/ml/processing/input/InputData', '%s_%s.csv'%(f,j))\n",
    "                feature_InputData_dataset_j = pd.read_csv(feature_InputData_path, names=model_complete_featureset, error_bad_lines=False, index_col=False)\n",
    "                feature_InputData_dataset=feature_InputData_dataset.append(feature_InputData_dataset_j)          \n",
    "        else:\n",
    "            feature_InputData_path=os.path.join('/opt/ml/processing/input/InputData', '%s.csv'%f)\n",
    "            feature_InputData_dataset = pd.read_csv(feature_InputData_path, names=model_complete_featureset, error_bad_lines=False, index_col=False)\n",
    "        fm_pd = pd.DataFrame()\n",
    "        for m in models:\n",
    "            print('Reading predicted data from model %s'%m)\n",
    "            if ftype=='Continuous':\n",
    "                pdf_dataset=pd.DataFrame()\n",
    "                for j in range(0,5):\n",
    "                    model_predicted_data_path =os.path.join('/opt/ml/processing/input/PartialDependency/%s'%m.replace('_','-'),'%s_%s.csv.out'%(f,j))\n",
    "                    pdf_dataset_i = pd.read_csv(model_predicted_data_path, names=['pd'], error_bad_lines=False, index_col=False)\n",
    "                    pdf_dataset=pdf_dataset.append(pdf_dataset_i)\n",
    "            else:\n",
    "                model_predicted_data_path =os.path.join('/opt/ml/processing/input/PartialDependency/%s'%m.replace('_','-'),'%s.csv.out'%f)                \n",
    "                pdf_dataset = pd.read_csv(model_predicted_data_path, names=['pd'], error_bad_lines=False, index_col=False)\n",
    "            #model feature partial dependency columns name\n",
    "            pd_column_name='%s_pd'%m\n",
    "            feature_InputData_dataset[pd_column_name]= pdf_dataset['pd'].values\n",
    "            \n",
    "            #average\n",
    "            fm_s = feature_InputData_dataset.groupby(f)[pd_column_name].mean()\n",
    "            fm_pd_model=pd.DataFrame({'value':fm_s.index, pd_column_name:fm_s.values})           \n",
    "            fm_pd_model['feature']=f\n",
    "            fm_pd_model = fm_pd_model[['feature','value',pd_column_name]]\n",
    "\n",
    "            fm_pd=pd.concat([fm_pd,fm_pd_model],axis=1)\n",
    "\n",
    "        #add text value for categorical encd columns\n",
    "        #assuming there is encoded (_encd ended) and original values in the dataset\n",
    "        fm_pd['value2']=fm_pd['value'].astype(str)\n",
    "        if '_encd' in f and f.replace('_encd','') in dataset.columns:\n",
    "            #unique combindation of codes and original values from the main dataset into list and then dictionary\n",
    "            dataset['dummy']= dataset[f.replace('_encd','')] +'-'+ dataset[f].astype(str)\n",
    "            unique_comb_l=dataset['dummy'].unique().tolist()\n",
    "            unique_comb_value=[i.split('-', 1)[0] for i in unique_comb_l]\n",
    "            unique_comb_key=[i.split('-', 1)[1] for i in unique_comb_l]\n",
    "            unique_comb_dict = dict(zip(unique_comb_key, unique_comb_value))\n",
    "            #replace value2 in the feature values and partial dependencies\n",
    "            fm_pd['value2'].replace(unique_comb_dict, inplace=True)\n",
    "        \n",
    "        #join all features in one dataset    \n",
    "        all_fm_pd=all_fm_pd.append(fm_pd)\n",
    "       \n",
    "    #saving final output    \n",
    "    all_fm_pd.to_csv(output_data_path,header=True ,index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker:Creating processing-job with name sagemaker-scikit-learn-2020-12-31-20-52-09-867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2020-12-31-20-52-09-867\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://kdproperty/Data/dwelling_basedata_v4.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://kdproperty/Data/PartialDependencyInputData/PartDepFWC', 'LocalPath': '/opt/ml/processing/input/InputData', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-3', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://kdproperty/PartialDependency/FWaterClaims', 'LocalPath': '/opt/ml/processing/input/PartialDependency/FWaterClaims', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-757107622481/sagemaker-scikit-learn-2020-12-31-20-52-09-867/input/code/postprocessingPartialDependencyData.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'output', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://kdproperty/Data/PartialDependencyOutputData/PartDepFWC', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "processors=list()\n",
    "\n",
    "featureset=Features['Feature'].tolist()\n",
    "featuretypes=Features['Type'].tolist()\n",
    "models=PredictedData['Model'].tolist()\n",
    "\n",
    "data_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type=instance_type,\n",
    "                                     instance_count=instance_count)\n",
    "\n",
    "data_processor.run(code='postprocessingPartialDependencyData.py',\n",
    "                        inputs=inputs,\n",
    "                        outputs=[ProcessingOutput(output_name='output', source='/opt/ml/processing/output', destination='s3://%s%sPartialDependencyOutputData/%s'%(bucket,path_to_data_file,Experiment_name)),                                                          \n",
    "                                ],\n",
    "                        arguments=['--data_file',data_file,\n",
    "                                 '--models',','.join(models).replace(' ',''),\n",
    "                                 '--model_complete_featureset',','.join(model_complete_featureset).replace(' ',''),\n",
    "                                 '--featureset', ','.join(featureset).replace(' ',''),\n",
    "                                 '--featuretypes', ','.join(featuretypes).replace(' ','')],\n",
    "                        experiment_config = {\n",
    "        'ExperimentName': Experiment_name ,\n",
    "        'TrialName' : Trial_name,\n",
    "        'TrialComponentDisplayName' : '%s'%(Trial_name,),},\n",
    "                        wait=False\n",
    "                        )\n",
    "processors.append(data_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing job sagemaker-scikit-learn-2020-12-31-20-52-09-867 status: InProgress\n",
      "Continue waiting...\n",
      "Processing job sagemaker-scikit-learn-2020-12-31-20-52-09-867 status: InProgress\n",
      "Continue waiting...\n",
      "Processing job sagemaker-scikit-learn-2020-12-31-20-52-09-867 status: InProgress\n",
      "Continue waiting...\n",
      "All Processing Jobs are Completed\n"
     ]
    }
   ],
   "source": [
    "#wait till the rest of processing jobs complete\n",
    "eu.wait_processing_jobs(processors=processors,check_every_sec=10,print_every_n_output=10,wait_min=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial Component</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PartDepFWC-PostProcessing</td>\n",
       "      <td>s3://kdproperty/Data/PartialDependencyOutputDa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Trial Component  \\\n",
       "0  PartDepFWC-PostProcessing   \n",
       "\n",
       "                                                Data  \n",
       "0  s3://kdproperty/Data/PartialDependencyOutputDa...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=Experiment_name\n",
    ")\n",
    "trial_comp_ds = trial_component_analytics.dataframe()\n",
    "trial_ds=trial_comp_ds[trial_comp_ds['DisplayName'].str.contains(Trial_name)].copy()\n",
    "trial_ds=trial_ds[['DisplayName','output - Value']]\n",
    "trial_ds.columns=['Trial Component','Data']\n",
    "trial_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving into the Experiment log location of the created  dataset\n",
    "eu.SaveToExperimentLog(Experiments_file, '%s OutputData'%Experiment_name, trial_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "#read data from S3 and visualize and save to a log\n",
    "#header as hardcoded in postprocessingPartialDependencyData.py: feature name, feature value, models partial dependency value (as we cofigured in the experiment), feature original value if encoded\n",
    "#the output file name (required in this case) is data.csv, hardcoded in postprocessingPartialDependencyData.py\n",
    "pdf_dataset = pd.read_csv(trial_ds['Data'][0]+'/data.csv',  error_bad_lines=False, index_col=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving into the Experiment log or load to redshift directly\n",
    "eu.SaveToExperimentLog(Experiments_file, '%s Data'%Experiment_name, pdf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "      <th>FWaterClaims_pd</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>2.346939</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>2.346939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>4.693878</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>4.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>7.040816</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>7.040816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cal_year-yearbuilt</td>\n",
       "      <td>9.387755</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>9.387755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature     value  FWaterClaims_pd    value2\n",
       "0  cal_year-yearbuilt  0.000000         0.000538  0.000000\n",
       "1  cal_year-yearbuilt  2.346939         0.000538  2.346939\n",
       "2  cal_year-yearbuilt  4.693878         0.000599  4.693878\n",
       "3  cal_year-yearbuilt  7.040816         0.000686  7.040816\n",
       "4  cal_year-yearbuilt  9.387755         0.001009  9.387755"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dataset['pd']=0\n",
    "for m in models:\n",
    "    pdf_dataset['pd'] = pdf_dataset['pd'] + pdf_dataset['%s_pd'%m]\n",
    "pdf_dataset['pd'] = pdf_dataset['pd']/len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization Partial Dependency with bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook()\n",
    "from bokeh.plotting import  figure, show\n",
    "from bokeh.models import HoverTool   \n",
    "class HoverHelper():\n",
    "\n",
    "    def hovertool(self):\n",
    "        tooltips = [\n",
    "            ('pd','@pd'),\n",
    "            ('value','@value2'),\n",
    "        ]\n",
    "        ht = HoverTool(tooltips=tooltips)\n",
    "        return ht\n",
    "    def tools(self, standard_tools='pan,crosshair,wheel_zoom,zoom_in,zoom_out,undo,reset'):\n",
    "        return [self.hovertool(), standard_tools]\n",
    "hover = HoverHelper()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"c9e4ec53-fba2-458a-96e1-178ca35eb325\" data-root-id=\"1003\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"31c5e324-daaa-4fab-8ad8-c037a30337cc\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1014\"}],\"center\":[{\"id\":\"1017\"},{\"id\":\"1021\"}],\"left\":[{\"id\":\"1018\"}],\"plot_height\":400,\"plot_width\":900,\"renderers\":[{\"id\":\"1042\"}],\"title\":{\"id\":\"1004\"},\"toolbar\":{\"id\":\"1029\"},\"x_range\":{\"id\":\"1006\"},\"x_scale\":{\"id\":\"1010\"},\"y_range\":{\"id\":\"1008\"},\"y_scale\":{\"id\":\"1012\"}},\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"axis\":{\"id\":\"1018\"},\"dimension\":1,\"ticker\":null},\"id\":\"1021\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"CrosshairTool\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data\":{\"FWaterClaims_pd\":{\"__ndarray__\":\"EnFWk9CkQT8ScVaT0KRBP/y6v0TyoEM/aZ43sut4Rj9fvn1rzohQP3PZPYr0UFc/7niBXMtKWT/acu+SJlNbP9PMSygvGF4/iLHOI0tBYT9X5q9CYodgP0z6BCrzf2A/vTFqTWh/YD+IqyCWXQFcP9r15Ex7SFo/EE292cuBWD9lbI8y//lXP+dfeaDDNFc/OM3EYoEpVz+MfjgTr9ZWPyp5w8TG1VY/MmjFkqqGVj/qAjnZX35WPwqdQKsRN1M//XHbvHQXUz+3l5FwmrpSP1lztMF2XFI/Z6z4L//RST+cKQa4XYZIP2A+vMQDh0g/YD68xAOHSD9Pi0sCAoZIP2VPPxXPtkc/pzF1JKiqRz+yo2uPO3VHP2Wlj1JFvUc/ojLiklXSRz+seWNZSdJHP+2TT8HOpUU/J8ZGhSUJQj8nxkaFJQlCP3Q1yZmhDEA/NkMVrhSIPj8/VcRIpbg7Pz9VxEiluDs/Ee8JKvz8Oz+sO7p2pzo8P1N4wBnVQzw/u9OwVu2yQT/OP/GOh/NBPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[50]},\"feature\":[\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\",\"cal_year-yearbuilt\"],\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"pd\":{\"__ndarray__\":\"EnFWk9CkQT8ScVaT0KRBP/y6v0TyoEM/aZ43sut4Rj9fvn1rzohQP3PZPYr0UFc/7niBXMtKWT/acu+SJlNbP9PMSygvGF4/iLHOI0tBYT9X5q9CYodgP0z6BCrzf2A/vTFqTWh/YD+IqyCWXQFcP9r15Ex7SFo/EE292cuBWD9lbI8y//lXP+dfeaDDNFc/OM3EYoEpVz+MfjgTr9ZWPyp5w8TG1VY/MmjFkqqGVj/qAjnZX35WPwqdQKsRN1M//XHbvHQXUz+3l5FwmrpSP1lztMF2XFI/Z6z4L//RST+cKQa4XYZIP2A+vMQDh0g/YD68xAOHSD9Pi0sCAoZIP2VPPxXPtkc/pzF1JKiqRz+yo2uPO3VHP2Wlj1JFvUc/ojLiklXSRz+seWNZSdJHP+2TT8HOpUU/J8ZGhSUJQj8nxkaFJQlCP3Q1yZmhDEA/NkMVrhSIPj8/VcRIpbg7Pz9VxEiluDs/Ee8JKvz8Oz+sO7p2pzo8P1N4wBnVQzw/u9OwVu2yQT/OP/GOh/NBPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[50]},\"value\":{\"__ndarray__\":\"AAAAAAAAAACyPjTWh8YCQLI+NNaHxhJAC15OwcspHECyPjTWh8YiQF1OwcspeCdAC15OwcspLEDctm3btm0wQLQ+NNaHxjJAicb60FgfNUBdTsHLKXg3QDbWh8b60DlAC15OwcspPEDf5RS8nII+QNy2bdu2bUBAx/rQWB+aQUC0PjTWh8ZCQJqCl1Pw8kNAicb60FgfRUBzCl5OwUtGQF1OwcspeEdASpIkSZKkSEA21ofG+tBJQCIa60Nj/UpAC15OwcspTED2obE+NFZNQOPlFLycgk5AzCl4OQWvT0Dctm3btm1QQNFYHxrrA1FAx/rQWB+aUUC8nIKXUzBSQLM+NNaHxlJAqODlFLxcU0CcgpdT8PJTQJQkSZIkiVRAiMb60FgfVUB+aKwPjbVVQHMKXk7BS1ZAaKwPjfXhVkBdTsHLKXhXQFLwcgpeDlhASpIkSZKkWEA/NNaHxjpZQDbWh8b60FlAK3g5BS9nWkAhGutDY/1aQBW8nIKXk1tAC15OwcspXEAAAAAAAMBcQA==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[50]},\"value2\":{\"__ndarray__\":\"AAAAAAAAAACyPjTWh8YCQLI+NNaHxhJAC15OwcspHECyPjTWh8YiQF1OwcspeCdAC15OwcspLEDctm3btm0wQLQ+NNaHxjJAicb60FgfNUBdTsHLKXg3QDbWh8b60DlAC15OwcspPEDf5RS8nII+QNy2bdu2bUBAx/rQWB+aQUC0PjTWh8ZCQJqCl1Pw8kNAicb60FgfRUBzCl5OwUtGQF1OwcspeEdASpIkSZKkSEA21ofG+tBJQCIa60Nj/UpAC15OwcspTED2obE+NFZNQOPlFLycgk5AzCl4OQWvT0Dctm3btm1QQNFYHxrrA1FAx/rQWB+aUUC8nIKXUzBSQLM+NNaHxlJAqODlFLxcU0CcgpdT8PJTQJQkSZIkiVRAiMb60FgfVUB+aKwPjbVVQHMKXk7BS1ZAaKwPjfXhVkBdTsHLKXhXQFLwcgpeDlhASpIkSZKkWEA/NNaHxjpZQDbWh8b60FlAK3g5BS9nWkAhGutDY/1aQBW8nIKXk1tAC15OwcspXEAAAAAAAMBcQA==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[50]}},\"selected\":{\"id\":\"1050\"},\"selection_policy\":{\"id\":\"1049\"}},\"id\":\"1038\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ZoomInTool\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"ZoomOutTool\"},{\"attributes\":{\"text\":\"cal_year-yearbuilt Partial Dependency\"},\"id\":\"1004\",\"type\":\"Title\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"pd\",\"@pd\"],[\"value\",\"@value2\"]]},\"id\":\"1002\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1006\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1027\",\"type\":\"UndoTool\"},{\"attributes\":{},\"id\":\"1028\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1008\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1010\",\"type\":\"LinearScale\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1002\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1025\"},{\"id\":\"1026\"},{\"id\":\"1027\"},{\"id\":\"1028\"}]},\"id\":\"1029\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"LinearScale\"},{\"attributes\":{\"axis_label\":\"Values\",\"formatter\":{\"id\":\"1048\"},\"ticker\":{\"id\":\"1015\"}},\"id\":\"1014\",\"type\":\"LinearAxis\"},{\"attributes\":{\"source\":{\"id\":\"1038\"}},\"id\":\"1043\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1015\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"value\"},\"y\":{\"field\":\"pd\"}},\"id\":\"1040\",\"type\":\"Circle\"},{\"attributes\":{\"data_source\":{\"id\":\"1038\"},\"glyph\":{\"id\":\"1040\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1041\"},\"selection_glyph\":null,\"view\":{\"id\":\"1043\"}},\"id\":\"1042\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis\":{\"id\":\"1014\"},\"ticker\":null},\"id\":\"1017\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1049\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"axis_label\":\"Partial Dependency\",\"formatter\":{\"id\":\"1046\"},\"ticker\":{\"id\":\"1019\"}},\"id\":\"1018\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1050\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1019\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"value\"},\"y\":{\"field\":\"pd\"}},\"id\":\"1041\",\"type\":\"Circle\"}],\"root_ids\":[\"1003\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"31c5e324-daaa-4fab-8ad8-c037a30337cc\",\"root_ids\":[\"1003\"],\"roots\":{\"1003\":\"c9e4ec53-fba2-458a-96e1-178ca35eb325\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1003"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f='cal_year-yearbuilt'\n",
    "p = figure(plot_width=900, \n",
    "               plot_height=400, \n",
    "               tools=hover.tools(),\n",
    "               x_axis_label='Values',\n",
    "               y_axis_label='Partial Dependency',\n",
    "               title='%s Partial Dependency'%f)\n",
    "p.circle(source=pdf_dataset[pdf_dataset['feature']==f], x='value', y='pd')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f='constructioncd_encd'\n",
    "values = pdf_dataset[pdf_dataset['feature']==f]['value2'].tolist()\n",
    "\n",
    "\n",
    "p = figure(plot_width=900, \n",
    "               plot_height=400, \n",
    "               tools=hover.tools(),\n",
    "               x_range=values,\n",
    "               x_axis_label='Values',\n",
    "               y_axis_label='Partial Dependency',\n",
    "               title='%s Partial Dependency'%f)\n",
    "p.vbar(source=pdf_dataset[pdf_dataset['feature']==f], x='value2', top='pd', width=0.70)\n",
    "\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f='landlordind'\n",
    "values = pdf_dataset[pdf_dataset['feature']==f]['value2'].tolist()\n",
    "\n",
    "\n",
    "p = figure(plot_width=900, \n",
    "               plot_height=400, \n",
    "               tools=hover.tools(),\n",
    "               x_range=values,\n",
    "               x_axis_label='Values',\n",
    "               y_axis_label='Partial Dependency',\n",
    "               title='%s Partial Dependency'%f)\n",
    "p.vbar(source=pdf_dataset[pdf_dataset['feature']==f], x='value2', top='pd', width=0.70)\n",
    "\n",
    "\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
